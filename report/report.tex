\documentclass[12pt]{article}

\usepackage{geometry}
 \geometry{
 a4paper,
 left=25mm,
 right=20mm,
 top=20mm,
 }
 
\usepackage{hyperref}
\usepackage{exercise}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{listings}

\graphicspath{ {images/} }

\lstset{language=python, firstline=37, lastline=45, title={Listing 1: Data structures for cellular automaton}}

\begin{document}

\title{
Computational Geometry and Digital Images \\
\textbf{fork-recognition}\\
Project report
}

\author{Etienne Moutot, Ievgeniia Oshurko}
\date{April 6, 2016}
\maketitle


\section{Introduction}  

There is a great interest in a problem of shape matching and shape recognition \cite{Zhang20041}. We propose our solution to this problem based on Machine Learning techniques applied to global shape desciptors.

To build a global shape descriptor which would capture geometry and topology of the shapes in a given class various contour-based and region-based features were assembled into a global bag-of-features.

We test this approach in the provided dataset that consists of $1 050$ images from $70$ different classes.

The following Python tools were used on a different stages of project:
\begin{itemize}
\item Library \texttt{scikit-image} for image processing purposes \url{http://scikit-image.org/}
\item Couple of utils were used from computer vision library \texttt{mahotas} \url{http://mahotas.readthedocs.org/en/latest/} (such as hit\&miss, thinning algorithms).
\item Library \texttt{scikit-learn} for machine learning and data preprocessing \url{http://scikit-learn.org/}
\end{itemize}


\section{Feature Engineering}

The extracted features capture the properties of shape: its topology and its geometry. In total, 38 features were developed:

\begin{itemize}
	\item Histogram of distance of the medial axis points from borders (\textbf{10 features} corresponding to 10 bins of histogram)
	\item Histogram of border curvature coefficients(\textbf{5 features} corresponding to 5 bins of histogram)
	\item Scaled area
	\item Solidity
	\item Extend
	\item Scaled major axis length
	\item Scaled minor axis length
	\item Histogram of medial axis straight lines length (\textbf{5 features} corresponding to 5 bins of histogram)
	\item Number of branches of medial axis skeleton
	\item Number of branched points of medial axis skeleton
	\item Scaled centroid displacement
	\item Asymmetry measures (\textbf{9 features} corresponding to horizontal and vertical flips, and rotation for 7 distinct angles)
\end{itemize} 

\subsection{Image preprocessing}
The images are pre-processed before we extract the features from them. There are two reasons for that:
\begin{itemize}
	\item We want to remove the noise from the image, because our features need to be robust to noise.
        \item We also want to remove the black holes that appears in some images.
        \item We want the shape to be white and the backgroud black (one of the rats is reversed).
\end{itemize}

For that we implemented 3 transfomations:
\begin{description}
	\item[Image padding]: The border of the image are just filled with a border of black pixels, in order to avoid problems when the shapes touch the border.
        \item[Shape filling]: The background is detected by the fact that it is the first connected component. Then it is fillend in black and the rest of the image (the main shape) is filled with white. With that we remove all the wholes in the image.
        \item[Smoothing]: The goal of this smoothing is to get rid of the noise at the border of the shape. We apply to the image a median filter, with as neighborhood a disk of a 7px diameter. After few tests, 7px seems to be a good compromise between smoothing and not loosing too much details. 
\end{description}

\subsection{Medial Axis}

We have extracted a lot of important features describing the shape from the \textit{Medial Axis Skeleton} (using implementation \texttt{skimage.morphology.medial\_axis}). 

Some skeletons of the shapes are illustrated by the figures below:

\includegraphics[scale=0.25]{fork_75.png}
\includegraphics[scale=0.25]{cup_476.png}

\vspace{12px}

\includegraphics[scale=0.25]{beetle_281.png}
\includegraphics[scale=0.25]{deer_79.png}

\subsubsection{Histogram of distance of the medial axis points from borders}

Each point $p$ of medial axis skeleton has the value $d(p)$ of distance to the border  assigned to it, this distance may also be seen as the radius of the maximal incircle with a center in $p$, and, in general, characterises the local thinkness of the shape in this point. Histogram of the skeleton distaces was used as a feature for our shape description, and it gives us the information about the distribution of local thinkness of the given shape.

\subsubsection{Medial axis straight lines}

Python implementation (\texttt{skimage.transform.probabilistic\_hough\_line}) of \textit{Probabilistic Hough Transform} \cite{Kiryati} was used to detect straight lines in medial axis skeleton. In this method straight line is represented by the segment perpendicular to it, parametrised by a pair $(\rho, \theta)$, where $\rho$ is a length of segment, and $\theta$ is an angle. Hough transform consists of two steps: parameter's plane of $(\rho, \theta)$ is divided into discrete grid (by parameter histogram bins), and the array representing this grid contains number of pixels close to the respective line, after this the exhaustive search of the parameters with maximum frequency is performed. Each time you find a pixel close to a particular parametrised line you increment the corresponding value of an array, this step is called incremental step, and it usually dominates the execution time of Hough transform.

The increment of the array's value for a given pair of parameters is called voting, and the Probabilistic Hough Transform makes an assumption that it is enough for a random subset of image pixel to vote to find the maximum frequency parameters. So for our dataset experimentally we have choosen to detect the lines, for which numer of pixels voting for the pair of parameters is more than 10 (threshold value $T=10$).

Detecting the straight lines of our medial axis skeleton helps us to capture its geometry. Images below illustrate the result of straight lines detection on some examples from our dataset.

\includegraphics[scale=0.6]{camel_764.png}
\vspace{12px}

\includegraphics[scale=0.6]{hammer_604.png}

We have used as a subset of our features the histogram (5 bins) of the lengths of the detected straight lines, which characterises the distribution of straight elements of medial axis skeleton for the given image.

\subsubsection{Quantitive features of skeleton}
To the quantive features of the skeleton the number of branches (number of end points in skeleton)

\subsection{Border Curvature}
\subsubsection{Histogram of border curvature coefficients}

\subsection{Volumetric Features}
\subsubsection{Scaled area}
\subsubsection{Solidity and extend}
\subsubsection{Scaled major and minor axes length}
\subsubsection{Scaled centroid displacement}

\includegraphics[scale=0.26]{fork_centroid.png}
\includegraphics[scale=0.26]{guitar_centroid.png}
\includegraphics[scale=0.26]{tree_centroid.png}

\subsection{Assymetry measures}
Distances from original image to its horizontal and vertical flips, to rotations for $k*\frac{\pi}{4}$
 
\section{Classification models}

Machine Learning techniques were used to build the model of shape recognition.  

\textit{Gaussian Naive Bayes Classifier} is

\textit{K-Nearest Neighbours Classifier} is

\textit{Support Vector Machines Classifier} is

Two kinds of test were performed on the training dataset:
\begin{itemize}
	\item \textbf{Score out of one} class which represents the accuracy score (number of samples with correctly assigned classes over all given samples).
	\item \textbf{Score out of ten} most probable classes which represents the number of samples for which the correct class was found in 10 most probable classes over all given samples.
\end{itemize}

\begin{center}
  \begin{tabular}{| l | c | c |}
    \hline
    \textbf{Classifier} & \textbf{Score out of one} & \textbf{Score out of ten}\\ \hline \hline
    \textit{Gaussian Naive Bayes} & \textit{0.79} & \textit{0.91} \\ \hline
	K-Nearest Neighbours (5 neighbours) & 0.63 & 0.87\\ \hline
	K-Nearest Neighbours (20 neighbours) & 0.51 & 0.92 \\ \hline
	SVM Classifier (linear kernel, C=1) & 0.68 & 0.90 \\ \hline
	\textit{SVM Classifier (RBF kernel, C=10, gamma=0.1)} & \textit{0.78} & \textit{0.93} \\ 
	\hline
  \end{tabular}
\end{center}

Parameters for SVM classifiers were chosen using the grid search according to the best score.

\section{Discussions}
Presented above feature vector is normalised and can be used as a shape descriptor  

\subsection{Performance}
\subsection{Robustness and scale/rotation invariance}

\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
